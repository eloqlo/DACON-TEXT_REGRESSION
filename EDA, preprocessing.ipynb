{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "- https://dacon.io/competitions/official/235875/codeshare/4520?page=1&dtype=recent\n",
    "의 EDA과정을 참고하였음.\n",
    "- https://wikidocs.net/92961\n",
    "의 한국어 맞춤법 교정 과정을 참조하였음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install pandas\n",
    "# !pip3 install matplotlib\n",
    "# !pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '~/Desktop/VSC/DACON/text_regression_task/dataset'   # MAC\n",
    "PATH = './dataset/' # Windows\n",
    "\n",
    "train_data = pd.read_csv(os.path.join(PATH, 'train.csv'), encoding='utf-8')     # 25000\n",
    "test_data = pd.read_csv(os.path.join(PATH, 'test.csv'), encoding='utf-8')       # 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "id      : 평점 인덱스\n",
    "reviews : 리뷰\n",
    "target  : 평점\n",
    "\"\"\"\n",
    "\n",
    "pd.set_option('display.max_row', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "print(train_data.head(10), end='\\n\\n')\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test Data Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.info())\n",
    "print()\n",
    "print(test_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 label별 균형 확인\n",
    "print('Train Label: ', train_data['target'].value_counts(), sep='\\n', end='\\n\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data의 Label 분류 결과<br>\n",
    "5점이 10000개<br>\n",
    "4점이 2500개<br>\n",
    "3점이 0개<br>\n",
    "2점이 8000개<br>\n",
    "1점이 4500개<br>\n",
    "\n",
    "--> label 불균형 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측지 확인\n",
    "print('Train Null: ', train_data.isnull().sum(), sep='\\n', end='\\n\\n')\n",
    "print('Test Null: ', test_data.isnull().sum(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 분포\n",
    "feature = train_data['target']\n",
    "\n",
    "plt.figure(figsize = (10, 7.5))\n",
    "plt.title('Label Counting', fontsize=20)\n",
    "\n",
    "temp = feature.value_counts()\n",
    "## temp.values -> 5 2 1 4\n",
    "plt.bar(temp.keys(), temp.values, width=0.5, color='b', alpha=0.5)\n",
    "plt.text(4.85, temp.values[0]+20, s=temp.values[0]) # 5\n",
    "plt.text(1.85, temp.values[1]+20, s=temp.values[1]) # 2\n",
    "plt.text(0.85, temp.values[2]+20, s=temp.values[2]) # 1\n",
    "plt.text(3.85, temp.values[3]+20, s=temp.values[3]) # 4\n",
    "\n",
    "plt.xticks(temp.keys(), fontsize=12)    # x축값\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar Correction\n",
    "\n",
    "- Py-Hanspell 이 띄어쓰기와 철자 둘 다 교정하기에, 우선 이를 전처리기로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyKoSpacing 띄어쓰기 교정 라이브러리\n",
    "# str형태만 입력으로 받을 수 있어, 병렬처리는 안된다.\n",
    "# !pip3 install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
    "\n",
    "# Py-Hanspell 맞춤법 교정 라이브러리\n",
    "# !pip3 install git+https://github.com/ssut/py-hanspell.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyKoSpacing : 띄어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent = '해당 라이브러리는 전희원 님이 개발하신 띄어쓰기가 되어있지 않은 문장을 띄어쓰기 된 문장으로 변환해주는 패키지 이다. 대용량 코퍼스를 학습하여 만들어진 띄어쓰기 딥러닝 모델로 준수한 성능을 가지고있다.'\n",
    "# new_sent = sent.replace(' ', '')\n",
    "# print(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pykospacing import Spacing\n",
    "# spacing = Spacing()\n",
    "# kospacing_sent = spacing(new_sent)\n",
    "\n",
    "# print(kospacing_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data['reviews'][80:100]\n",
    "# # train_data['reviews'][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_input = train_data['reviews'][21]\n",
    "# sample_result = spacing(sample_input)\n",
    "# print( sample_input, '\\n\\n', sample_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Py-Hanspell : 맞춤법 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanspell import spell_checker\n",
    "\n",
    "sample_input = train_data['reviews'][21]\n",
    "sample_result_spell = spell_checker.check(sample_input)\n",
    "print( sample_input, '\\n\\n', sample_result_spell.checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 병렬처리 테스트\n",
    "pi_ = ['앙녕', '앙녕하세요']\n",
    "output_spell = spell_checker.check(pi_)\n",
    "# print(output_spell)\n",
    "# list 로 병렬처리 된다.\n",
    "\n",
    "## 데이터프레임 객체도 병렬처리 지원하는지?\n",
    "pd_pi_ = pd.DataFrame(pi_)\n",
    "output_spell_pd = spell_checker.check(pd_pi_)\n",
    "# print(output_spell_pd)\n",
    "# list만 되는듯하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선, 맞춤법교정기가 문법과 띄어쓰기까지 교정한다 가정하고 pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    train_data.iloc[58],'\\n\\n',\n",
    "    train_data.iloc[93]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Test data Preprocessing - Grammer Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 불용어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_idx = [932,3093,4933,7784,9457,13134,15404,17440,17669,18047,19745,22504,24383]   # \"&\" 를 처리했음.\n",
    "\n",
    "# for i in wrong_idx:\n",
    "#     print('before -- ', train_data['reviews'][i])\n",
    "#     temp = train_data['reviews'][i].replace(\"&\",\"\")\n",
    "#     train_data['reviews'][i] = temp\n",
    "#     print('after -- ',train_data['reviews'][i])\n",
    "#     print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 전체 맞춤법 교정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing... This might take a while... : 100%|██████████| 25000/25000 [29:14<00:00, 14.25it/s] \n"
     ]
    }
   ],
   "source": [
    "# train_data 맞춤법 전처리\n",
    "from hanspell import spell_checker\n",
    "\n",
    "train_refined_reviews = []\n",
    "for i in tqdm(range(0,25000),desc='Preprocessing... This might take a while... '):\n",
    "    try:\n",
    "        temp = spell_checker.check(train_data.iloc[i]['reviews'])\n",
    "        train_refined_reviews.append(temp.checked)\n",
    "    except:\n",
    "        temp = train_data['reviews'][i].replace(\"&\",\"\")\n",
    "        temp = spell_checker.check(temp)\n",
    "        train_refined_reviews.append(temp.checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_refined_reviews)    # 25000\n",
    "train_data['reviews'] = train_refined_reviews\n",
    "del train_refined_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "train_data.to_csv('./dataset/preprocessed_train.csv', mode='w')\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing... This might take a while...: 100%|██████████| 25000/25000 [29:23<00:00, 14.17it/s]  \n"
     ]
    }
   ],
   "source": [
    "# test_data 맞춤법 전처리\n",
    "from hanspell import spell_checker\n",
    "\n",
    "test_refined_reviews = []\n",
    "for i in tqdm(range(0,25000),desc='Preprocessing... This might take a while...'):\n",
    "    try:\n",
    "        temp = spell_checker.check(test_data.iloc[i]['reviews'])\n",
    "        test_refined_reviews.append(temp.checked)\n",
    "    except:\n",
    "        temp = test_data['reviews'][i].replace(\"&\",\"\")\n",
    "        temp = spell_checker.check(temp)\n",
    "        test_refined_reviews.append(temp.checked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['reviews'] = test_refined_reviews\n",
    "del test_refined_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('./dataset/preprocessed_test.csv', mode='w')\n",
    "del test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Ethics-Korean')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7b8a9d296651b950055feafaab8f47ff1cee70807e6c570958d0b27d2589bac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
